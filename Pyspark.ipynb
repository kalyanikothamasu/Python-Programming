{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOz6Adx46T9JiiXxoYy8nGS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPRMUZXkoksZ","executionInfo":{"status":"ok","timestamp":1761001662939,"user_tz":420,"elapsed":1333,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"aad095f3-9cad-4954-8ac4-a944e9dcfb4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["   Customer_ID Customer_Name   Product     Level  Quantity  Price\n","0            1       Sahasra    Laptop      Gold         5    500\n","1            2        Sharan    Iphone      Gold         3    800\n","2            3        Satwik    Iwatch    Silver         7    300\n","3            4         Akhil      Ipod    Bronze         9    150\n","4            5       Prathyu  Mac-Book  Platnium         2   2000\n","+-----------+-------------+-------+-----+--------+-----+\n","|Customer_ID|Customer_Name|Product|Level|Quantity|Price|\n","+-----------+-------------+-------+-----+--------+-----+\n","|          1|      Sahasra| Laptop| Gold|       5|  500|\n","|          2|       Sharan| Iphone| Gold|       3|  800|\n","+-----------+-------------+-------+-----+--------+-----+\n","\n","+-----------+-------------+--------+--------+--------+-----+\n","|Customer_ID|Customer_Name| Product|   Level|Quantity|Price|\n","+-----------+-------------+--------+--------+--------+-----+\n","|          1|      Sahasra|  Laptop|    Gold|       5|  500|\n","|          2|       Sharan|  Iphone|    Gold|       3|  800|\n","|          3|       Satwik|  Iwatch|  Silver|       7|  300|\n","|          4|        Akhil|    Ipod|  Bronze|       9|  150|\n","|          5|      Prathyu|Mac-Book|Platnium|       2| 2000|\n","+-----------+-------------+--------+--------+--------+-----+\n","\n"]}],"source":["Customer_Data={'Customer_ID':[1,2,3,4,5],'Customer_Name':['Sahasra','Sharan','Satwik','Akhil','Prathyu'],\n","                 'Product':['Laptop','Iphone','Iwatch','Ipod','Mac-Book'],'Level':['Gold','Gold','Silver','Bronze','Platnium'],\n","                 'Quantity':[5,3,7,9,2],'Price':[500,800,300,150,2000]}\n","import pandas as pd\n","df=pd.DataFrame(Customer_Data)\n","print(df)\n","from pyspark.sql import DataFrame\n","from pyspark.sql.functions import col\n","from pyspark.sql import SparkSession\n","\n","# Initialize SparkSession\n","spark=SparkSession.builder.appName(\"Customer_Data\").getOrCreate()\n","\n","Input_data=spark.createDataFrame(df)\n","filterd_Data=Input_data.filter(col(\"Level\") == 'Gold')\n","filterd_Data.show()\n","Input_data.show()"]},{"cell_type":"code","source":["order_data = [\n","    (1001, 1, \"2025-10-20\", 750.50),\n","    (1002, 3, \"2025-10-20\", 120.00),\n","    (1003, 1, \"2025-10-21\", 45.99),\n","    (1004, 2, \"2025-10-21\", 980.75),\n","    (1005, 3, \"2025-10-22\", 250.00)\n","]\n","columns = [\"OrderID\", \"CustomerID\", \"OrderDate\", \"TotalAmount\"]\n","spark=spark.createDataFrame(data=order_data,schema=columns)\n","spark.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7GRSEFrrE0i","executionInfo":{"status":"ok","timestamp":1761003539343,"user_tz":420,"elapsed":910,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"5ff4cf50-124a-4284-8229-277a40647e18"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+----------+----------+-----------+\n","|OrderID|CustomerID| OrderDate|TotalAmount|\n","+-------+----------+----------+-----------+\n","|   1001|         1|2025-10-20|      750.5|\n","|   1002|         3|2025-10-20|      120.0|\n","|   1003|         1|2025-10-21|      45.99|\n","|   1004|         2|2025-10-21|     980.75|\n","|   1005|         3|2025-10-22|      250.0|\n","+-------+----------+----------+-----------+\n","\n"]}]},{"cell_type":"code","source":["employee_data={'Employee_Id':[101,102,103],'Employee_Name':['Sahasra','Sharan','Kalyani'],'Salary':[1000,2000,3000],'Department':['IT','HR','Finance']}\n","from pyspark.sql import DataFrame\n","from pyspark.sql.functions import col\n","from pyspark.sql import SparkSession\n","import pandas as pd\n","df=pd.DataFrame(employee_data)\n","print(df)\n","# Initialize SparkSession\n","spark=SparkSession.builder.appName(\"Employee_Data\").getOrCreate()\n","spark.createDataFrame(df).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-sGYJ9M_RHK","executionInfo":{"status":"ok","timestamp":1761004040719,"user_tz":420,"elapsed":649,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"0ddbd2e6-5840-44e6-9d78-4ea49da1b690"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["   Employee_Id Employee_Name  Salary Department\n","0          101       Sahasra    1000         IT\n","1          102        Sharan    2000         HR\n","2          103       Kalyani    3000    Finance\n","+-----------+-------------+------+----------+\n","|Employee_Id|Employee_Name|Salary|Department|\n","+-----------+-------------+------+----------+\n","|        101|      Sahasra|  1000|        IT|\n","|        102|       Sharan|  2000|        HR|\n","|        103|      Kalyani|  3000|   Finance|\n","+-----------+-------------+------+----------+\n","\n"]}]},{"cell_type":"code","source":["user_data={'username':['Sahasra','Sharan'],'Id':[1,2]}\n","import pandas as pd\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","from pyspark.sql import DataFrame # This import is not strictly needed for this cell but kept for context\n","\n","df=pd.DataFrame(user_data)\n","#print(df)\n","\n","# Initialize SparkSession (ensure this is only done once per notebook)\n","spark=SparkSession.builder.appName('userdata').getOrCreate()\n","\n","t=spark.createDataFrame(df)\n","#t.show()\n","\n","# The original filtering code is kept as it was correct, but the function definition was the source of error.\n","filtered_data=t.filter(col('Id')==1)\n","\n","# Corrected function definition (the user attempted to define this)\n","# This function takes a Spark DataFrame and an integer ID, and returns a filtered DataFrame.\n","def get_user_data_by_id(spark_df: DataFrame, user_id: int) -> DataFrame:\n","  \"\"\"Filters a Spark DataFrame by user ID.\"\"\"\n","  filtered_df = spark_df.filter(col('Id') == user_id)\n","  return filtered_df\n","  output=get_user_data_by_id(spark_df=t,user_id=1)\n","  print(\"final output:\",output.show())\n","  output.show(1)\n","\n","# Example of how to call the corrected function (optional, can be in a new cell)\n","# user_1_data = get_user_data_by_id(t, 1)\n","# user_1_data.show()"],"metadata":{"id":"YWr0oajgCWa9","executionInfo":{"status":"ok","timestamp":1761008742106,"user_tz":420,"elapsed":74,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Use the function defined in the previous cell to get data for user ID 1\n","user_1_data = get_user_data_by_id(t, 1)\n","\n","# Display the filtered data\n","user_1_data.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3ZhUAYNDJ4w","executionInfo":{"status":"ok","timestamp":1761008808638,"user_tz":420,"elapsed":382,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"ba7991be-3a82-4389-a421-6788e70e365f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+---+\n","|username| Id|\n","+--------+---+\n","| Sahasra|  1|\n","+--------+---+\n","\n"]}]}]}