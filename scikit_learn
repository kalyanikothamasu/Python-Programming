{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMR0gIenMKL865Yfh66vdC5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z9t5EGia2_H6","executionInfo":{"status":"ok","timestamp":1768031035673,"user_tz":480,"elapsed":5298,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"6c23dbaf-6b7d-4945-fa20-af14289f7ee4"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1]\n"]}],"source":["# 1. Import the model (we'll use a simple one called a Decision Tree)\n","from sklearn import tree\n","\n","# 2. Features (X): [Weight in grams, Texture (1 for Smooth, 0 for Bumpy)]\n","#    Target (y): [0 for Apple, 1 for Orange]\n","X = [[140, 1], [130, 1], [150, 0], [170, 0]]\n","y = [0, 0, 1, 1]\n","\n","# 3. Instantiate the model\n","clf = tree.DecisionTreeClassifier()\n","\n","# 4. Fit (Train the model)\n","clf = clf.fit(X, y)\n","\n","# 5. Predict (Let's test a new fruit: 160g and Bumpy)\n","print(clf.predict([[160, 0]]))\n","# Output: [1] -> The model thinks it's an Orange!"]},{"cell_type":"code","source":["# 2. How to \"See\" What’s Available\n","# If you want to see the list of every dataset function available in your version of Sklearn, you can run this simple two-line command in your Python environment:\n","\n","# Python\n","\n","from sklearn import datasets\n","print(dir(datasets))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aK8_bfYd3lac","executionInfo":{"status":"ok","timestamp":1768031190446,"user_tz":480,"elapsed":484,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"058da731-aa56-4c12-b906-3b02d7b420cf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_arff_parser', '_base', '_california_housing', '_covtype', '_kddcup99', '_lfw', '_olivetti_faces', '_openml', '_rcv1', '_samples_generator', '_species_distributions', '_svmlight_format_fast', '_svmlight_format_io', '_twenty_newsgroups', 'clear_data_home', 'dump_svmlight_file', 'fetch_20newsgroups', 'fetch_20newsgroups_vectorized', 'fetch_california_housing', 'fetch_covtype', 'fetch_file', 'fetch_kddcup99', 'fetch_lfw_pairs', 'fetch_lfw_people', 'fetch_olivetti_faces', 'fetch_openml', 'fetch_rcv1', 'fetch_species_distributions', 'get_data_home', 'load_breast_cancer', 'load_diabetes', 'load_digits', 'load_files', 'load_iris', 'load_linnerud', 'load_sample_image', 'load_sample_images', 'load_svmlight_file', 'load_svmlight_files', 'load_wine', 'make_biclusters', 'make_blobs', 'make_checkerboard', 'make_circles', 'make_classification', 'make_friedman1', 'make_friedman2', 'make_friedman3', 'make_gaussian_quantiles', 'make_hastie_10_2', 'make_low_rank_matrix', 'make_moons', 'make_multilabel_classification', 'make_regression', 'make_s_curve', 'make_sparse_coded_signal', 'make_sparse_spd_matrix', 'make_sparse_uncorrelated', 'make_spd_matrix', 'make_swiss_roll', 'textwrap']\n"]}]},{"cell_type":"code","source":["from sklearn.datasets import get_data_home\n","\n","print(get_data_home())\n","# On Windows, it usually looks like: C:\\Users\\Name\\scikit_learn_data\n","# On Mac/Linux, it usually looks like: /home/name/scikit_learn_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFoJ_Pfr4DWR","executionInfo":{"status":"ok","timestamp":1768031277566,"user_tz":480,"elapsed":12,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"ea177f17-de8e-463e-bc80-2b36c35cfa74"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/root/scikit_learn_data\n"]}]},{"cell_type":"code","source":["# That is a very observant question! You’ve spotted one of the \"utility\" functions in the dataset module.\n","# get_data_home() is like asking Scikit-learn,\n","#  \"Where is the warehouse where you store all the big datasets I download?\"\n","#  1. What does it actually do?When you use fetch_ commands (like fetch_california_housing),\n","#  the data is too big to be kept in the library code. Scikit-learn downloads it to\n","#   your computer's hard drive so you don't have to download it again next time.get_data_home()\n","#    simply returns the folder path where that data is being saved.Pythonfrom sklearn.datasets\n","#    import get_data_home\n","\n","# print(get_data_home())\n","# On Windows, it usually looks like: C:\\Users\\Name\\scikit_learn_data\n","# On Mac/Linux, it usually looks like: /home/name/scikit_learn_data\n","# 2. Why would you ever use it?For a beginner, you won't need it daily, but it's helpful\n","# for three reasons:Housekeeping: If your hard drive is getting full\n","#  because you downloaded 50 massive datasets, you can find the folder\n","#   and delete them.Debugging: If a download fails or a file gets corrupted,\n","#   you can go to that path and clear the folder.Redirection: You can actually\n","#   tell Scikit-learn to use a different folder (like an external drive) by passing a path to it:\n","#    get_data_home(data_home=\"D:/my_ml_data\").Step 5: The \"Golden Rule\"\n","#    of Machine LearningNow that we've found where the data lives, we have to\n","#     talk about how to use it properly.If I give you a practice exam and the\n","#     exact same questions appear on the final exam, I haven't tested your intelligence—I've\n","#      only tested your memory. Machine Learning is the same.To prevent \"cheating\"\n","#       (called Overfitting), we must split our data.The train_test_split\n","#       toolScikit-learn has a famous function for this. We take our $X$ (features) and $y$ (target)\n","# and chop them into two pieces:Training Set:\n","# The data the model \"studies.\"Testing Set: The \"final exam\" the model has never seen before.\n","\n","from sklearn.model_selection import train_test_split\n","\n","# We split it! Usually 80% for training, 20% for testing.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"],"metadata":{"id":"IeRMzKAS41hp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==========================================\n","# STAIR 1: IMPORT THE TOOLS\n","# ==========================================\n","\n","# Why required: These are the fundamental building blocks (modules and functions) needed for our machine learning task.\n","#               Importing them allows us to use their functionalities in our code.\n","\n","# Module: sklearn.datasets\n","# Use Case: Provides various standard datasets for machine learning practice and benchmarking.\n","from sklearn.datasets import load_iris\n","\n","# Module: sklearn.model_selection\n","# Use Case: Contains utilities for splitting datasets into training and testing subsets,\n","#           which is crucial for evaluating model performance reliably.\n","from sklearn.model_selection import train_test_split\n","\n","# Module: sklearn.tree\n","# Use Case: Provides various tree-based models, including the DecisionTreeClassifier.\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Module: sklearn.metrics\n","# Use Case: Offers functions for evaluating the performance of machine learning models.\n","from sklearn.metrics import accuracy_score\n","\n","# ==========================================\n","# STAIR 2: LOAD AND PREPARE DATA\n","# ==========================================\n","\n","# Function: load_iris()\n","# Use Case: Loads the famous Iris plant dataset, which is a classic dataset for classification.\n","#           It's used here as a simple, built-in example to demonstrate the ML pipeline.\n","# Input: None\n","# Output: A Bunch object (similar to a dictionary) containing the data, target, feature names, etc.\n","iris = load_iris()\n","\n","# Object: iris.data (Features - X)\n","# Use Case: Stores the numerical features (measurements like sepal length, petal width) of each iris flower.\n","#           This is the input data that the model will use to learn patterns.\n","# Properties: A 2D NumPy array, where each row is a sample and each column is a feature.\n","# Input: Data loaded from load_iris()\n","# Output: The feature matrix (X)\n","X = iris.data    # The Features (sepal/petal measurements)\n","\n","# Object: iris.target (Target - y)\n","# Use Case: Stores the corresponding labels (species of the flower) for each set of features.\n","#           This is what the model tries to predict.\n","# Properties: A 1D NumPy array of integers (0, 1, or 2, representing different species).\n","# Input: Target labels loaded from load_iris()\n","# Output: The target vector (y)\n","y = iris.target  # The Target (the flower species)\n","\n","# Function: train_test_split(X, y, test_size=0.2, random_state=42)\n","# Why required: This is the \"Golden Rule\" of Machine Learning. It's essential to split data\n","#               into training and testing sets to prevent overfitting (where a model memorizes\n","#               the training data instead of learning general patterns).\n","#               The model will be trained on `X_train`, `y_train` and evaluated on `X_test`, `y_test`.\n","# Properties:\n","#   - test_size: The proportion of the dataset to include in the test split (here, 20%).\n","#   - random_state: An integer to ensure reproducibility of the split. If you run the code again\n","#                   with the same random_state, you'll get the exact same split.\n","# Input: Feature matrix (X), target vector (y), test set size, and a random seed.\n","# Output: Four NumPy arrays: X_train, X_test, y_train, y_test.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ==========================================\n","# STAIR 3: THE UNIVERSAL PATTERN\n","# ==========================================\n","\n","# 1. Instantiate: Create the \"brain\"\n","# Object: DecisionTreeClassifier()\n","# Use Case: Creates an instance of the Decision Tree classification model. This initializes\n","#           the model with its default parameters (or custom ones if provided).\n","# Properties: An object capable of learning from data and making predictions.\n","# Input: None (or hyperparameters like max_depth, criterion, etc., if specified).\n","# Output: An untrained DecisionTreeClassifier object.\n","model = DecisionTreeClassifier()\n","\n","# 2. Fit: Teach the model using the training data\n","# Method: model.fit(X_train, y_train)\n","# Use Case: This is the training step. The model learns patterns and relationships\n","#           from the training features (X_train) to predict the training targets (y_train).\n","# Logic: Internally, the Decision Tree algorithm builds a tree structure based on the training data.\n","# Input: Training features (X_train) and corresponding training targets (y_train).\n","# Output: The trained model object itself (returns self).\n","model.fit(X_train, y_train)\n","\n","# 3. Predict: Ask the model to guess the species of the test data\n","# Method: model.predict(X_test)\n","# Use Case: Uses the trained model to make predictions on new, unseen data (the test set).\n","#           This is how we assess if the model can generalize to new examples.\n","# Logic: The model traverses its learned decision tree for each sample in X_test to determine a prediction.\n","# Input: Test features (X_test).\n","# Output: A NumPy array of predicted target labels for the X_test samples.\n","predictions = model.predict(X_test)\n","\n","# ==========================================\n","# STAIR 4: EVALUATE THE RESULTS\n","# ==========================================\n","\n","# Function: accuracy_score(y_test, predictions)\n","# Use Case: Calculates the proportion of correctly classified samples. It's a common metric\n","#           to evaluate the performance of classification models.\n","# Logic: Compares each predicted label in `predictions` with the true label in `y_test`\n","#        and calculates the ratio of correct matches to total samples.\n","# Input: True target labels (y_test) and the model's predicted labels (predictions).\n","# Output: A float representing the accuracy score (e.g., 0.95 for 95% accuracy).\n","accuracy = accuracy_score(y_test, predictions)\n","\n","print(\"--- Scikit-Learn Tutorial Results ---\")\n","print(f\"Total samples in dataset: {len(X)}\")\n","print(f\"Samples used for training: {len(X_train)}\")\n","print(f\"Samples used for testing: {len(X_test)}\")\n","print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n","print(\"-------------------------------------\")\n","\n","# BONUS: Let's predict a single \"mystery\" flower\n","# Use Case: Demonstrates how to use the trained model to predict the class of a single new data point.\n","# Input: A new data point, formatted as a 2D array (even for a single sample, it needs to be 2D\n","#        to match the expected input shape of the model, which expects multiple samples).\n","# Output: A list containing the predicted class label (e.g., [0] for species 0).\n","mystery_flower = [[5.1, 3.5, 1.4, 0.2]] # Example features for a new flower\n","guess = model.predict(mystery_flower)\n","\n","# Object: iris.target_names\n","# Use Case: Provides the human-readable names for the target classes (e.g., 'setosa', 'versicolor', 'virginica').\n","# Logic: `guess` will be a NumPy array like `[0]`. `iris.target_names[0]` retrieves the name for class 0.\n","# Input: The numerical prediction from the model.\n","# Output: The string name of the predicted species.\n","species_name = iris.target_names[guess][0]\n","\n","print(f\"The model predicts the mystery flower is: {species_name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJB4kboQ58-5","executionInfo":{"status":"ok","timestamp":1768032112305,"user_tz":480,"elapsed":127,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"10060b25-e15a-4709-e38a-da23ef019dae"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Scikit-Learn Tutorial Results ---\n","Total samples in dataset: 150\n","Samples used for training: 120\n","Samples used for testing: 30\n","Model Accuracy: 100.00%\n","-------------------------------------\n","The model predicts the mystery flower is: setosa\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70d1b813","executionInfo":{"status":"ok","timestamp":1768032304455,"user_tz":480,"elapsed":44,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"c83ac5b0-de4e-42fa-9b33-903c2b89ae69"},"source":["import sklearn.tree\n","\n","# Get all members of the sklearn.tree module\n","tree_members = dir(sklearn.tree)\n","\n","# Filter for names that typically indicate a classifier class\n","# This often includes names ending with 'Classifier' or similar patterns.\n","classifiers = []\n","for member_name in tree_members:\n","    if member_name.endswith('Classifier') or member_name.endswith('TreeClassifier'):\n","        # You can add more specific checks here if needed,\n","        # e.g., checking if it's actually a class and inherits from BaseEstimator.\n","        # For this purpose, checking the name is a good starting point.\n","        classifiers.append(member_name)\n","\n","print(\"Classifiers found in sklearn.tree:\")\n","for clf in classifiers:\n","    print(f\"- {clf}\")\n","\n","print(f\"\\nTotal classifiers in sklearn.tree: {len(classifiers)}\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Classifiers found in sklearn.tree:\n","- DecisionTreeClassifier\n","- ExtraTreeClassifier\n","\n","Total classifiers in sklearn.tree: 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"eb66d7b3"},"source":["### Class Blueprint: Understanding Classes, Attributes, and Methods\n","\n","A class is a blueprint for creating objects (a particular data structure), providing initial values for state (member variables or attributes), and implementations of behavior (member functions or methods). Think of it like a cookie cutter: the class is the cutter, and the cookies are the objects (instances) created from it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"343af821","executionInfo":{"status":"ok","timestamp":1768031921030,"user_tz":480,"elapsed":58,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"efe0376d-2387-43bf-e458-f334c4958d84"},"source":["# 1. Class Definition\n","# A class is defined using the 'class' keyword, followed by the class name.\n","# Class names typically follow CapWords convention (e.g., MyClass, CarEngine).\n","class MyExampleClass:\n","    # 2. Class Attributes (Static/Shared Attributes)\n","    # These attributes are shared by all instances of the class. They are defined directly\n","    # inside the class but outside any methods.\n","    # Why used: For data that is common to all objects of this class (e.g., a constant,\n","    # a default value, or a counter for instances).\n","    # Properties: Accessible directly via the class name (e.g., MyExampleClass.species)\n","    # Logic: Simple assignment.\n","    # Input: N/A (defined at class creation).\n","    # Output: The stored value when accessed.\n","    class_attribute_type = \"Blueprint Example\"\n","    instance_count = 0 # To track how many objects are created\n","\n","    # 3. The Constructor Method: __init__\n","    # This special method is automatically called when a new instance of the class is created.\n","    # It's used to initialize the object's state (instance attributes).\n","    # Why used: To set up the initial characteristics/data for each individual object.\n","    # Properties: Must be named __init__.\n","    # Logic: Takes 'self' (a reference to the instance being created) as its first argument,\n","    #        followed by any other parameters needed to initialize the object.\n","    # Input: 'self' (implicitly passed), and any custom arguments (e.g., name, value).\n","    # Output: None (it initializes the object itself).\n","    def __init__(self, name: str, initial_value: int):\n","        # 4. Instance Attributes\n","        # These attributes belong to a specific instance of the class. Each object\n","        # will have its own copy of these attributes.\n","        # Why used: To store data unique to each object.\n","        # Properties: Accessible via the instance (e.g., my_object.name).\n","        # Logic: Assigned within the __init__ method using 'self.attribute_name = value'.\n","        # Input: The values passed during object creation.\n","        # Output: The stored value when accessed from an instance.\n","        self.name = name\n","        self._current_value = initial_value # Using '_' for a 'protected' attribute convention\n","        self.status = \"Active\"\n","        MyExampleClass.instance_count += 1 # Increment class attribute on new instance\n","        print(f\"Instance '{self.name}' created with initial value {self._current_value}.\")\n","\n","    # 5. Regular Method\n","    # A function defined inside a class that operates on the object's data.\n","    # Why used: To define behaviors or actions that an object can perform.\n","    # Properties: Takes 'self' as its first argument to access instance attributes.\n","    # Logic: Contains code to perform a specific task.\n","    # Input: 'self' (implicitly passed), and any custom arguments for the method.\n","    # Output: Can return a value, print output, or modify instance state.\n","    def increment_value(self, amount: int = 1) -> None:\n","        \"\"\"Increments the internal value by the specified amount.\"\"\"\n","        if amount < 0:\n","            print(\"Cannot increment by a negative amount.\")\n","            return\n","        self._current_value += amount\n","        print(f\"Value for '{self.name}' incremented to {self._current_value}.\")\n","\n","    # 6. Another Regular Method (with return value)\n","    def get_info(self) -> str:\n","        \"\"\"Returns a string summary of the instance's state.\"\"\"\n","        return f\"Name: {self.name}, Current Value: {self._current_value}, Status: {self.status}\"\n","\n","    # 7. Property (using @property decorator)\n","    # A way to define methods that can be accessed like attributes.\n","    # Why used: To encapsulate logic for getting, setting, or deleting an attribute,\n","    #           making the attribute access look natural while adding validation or computation.\n","    # Properties: Accessed without parentheses (e.g., my_object.value).\n","    # Logic: The getter method returns the attribute's value. Optional setter/deleter methods can be defined.\n","    # Input: None for getter; value for setter.\n","    # Output: The computed or retrieved value for getter; None for setter.\n","    @property\n","    def value(self) -> int:\n","        \"\"\"Getter for the 'value' property.\"\"\"\n","        print(\"Accessing value property...\")\n","        return self._current_value\n","\n","    @value.setter\n","    def value(self, new_value: int) -> None:\n","        \"\"\"Setter for the 'value' property with validation.\"\"\"\n","        if not isinstance(new_value, int):\n","            raise TypeError(\"Value must be an integer\")\n","        if new_value < 0:\n","            print(\"Warning: Value cannot be negative. Setting to 0.\")\n","            self._current_value = 0\n","        else:\n","            self._current_value = new_value\n","            print(f\"Value for '{self.name}' updated to {self._current_value}.\")\n","\n","    # 8. Special Method: __str__ (String Representation)\n","    # Defines what happens when you try to convert an object to a string (e.g., print(obj)).\n","    # Why used: To provide a human-readable representation of the object.\n","    # Properties: Must be named __str__.\n","    # Logic: Returns a string.\n","    # Input: 'self' (implicitly passed).\n","    # Output: A string.\n","    def __str__(self) -> str:\n","        return f\"<MyExampleClass Object: Name='{self.name}', Value={self._current_value}>\"\n","\n","# --- How to use the Class (Instantiation and Interaction) ---\n","print(\"\\n--- Creating Instances ---\")\n","# Creating objects (instances) from the class blueprint\n","# Input: Arguments for the __init__ method.\n","# Output: A new object of MyExampleClass.\n","obj1 = MyExampleClass(\"First Object\", 10)\n","obj2 = MyExampleClass(\"Second Object\", 20)\n","\n","print(\"\\n--- Accessing Class Attributes ---\")\n","# Class attributes are accessed directly via the class name\n","print(f\"Class attribute type: {MyExampleClass.class_attribute_type}\")\n","print(f\"Total instances created: {MyExampleClass.instance_count}\")\n","\n","print(\"\\n--- Accessing Instance Attributes ---\")\n","# Instance attributes are accessed via the object name\n","print(f\"Obj1's name: {obj1.name}, status: {obj1.status}\")\n","print(f\"Obj2's name: {obj2.name}, status: {obj2.status}\")\n","\n","print(\"\\n--- Calling Methods ---\")\n","# Calling methods on obj1\n","obj1.increment_value()\n","obj1.increment_value(5)\n","\n","# Calling methods on obj2\n","obj2.increment_value(amount=10)\n","\n","print(\"\\n--- Using the get_info method ---\")\n","# Input: None (implicitly self)\n","# Output: A descriptive string\n","print(f\"Info for obj1: {obj1.get_info()}\")\n","print(f\"Info for obj2: {obj2.get_info()}\")\n","\n","print(\"\\n--- Using the Property (Getter) ---\")\n","# Accessing 'value' like an attribute, which calls the @property getter\n","# Input: None\n","# Output: The current value of _current_value\n","print(f\"Obj1's current value (via property): {obj1.value}\")\n","\n","print(\"\\n--- Using the Property (Setter) ---\")\n","# Setting 'value' like an attribute, which calls the @value.setter\n","# Input: A new integer value\n","# Output: Prints a message, potentially modifies _current_value\n","obj1.value = 100\n","print(f\"Obj1's updated value: {obj1.value}\")\n","obj1.value = -5 # Example of setter validation\n","print(f\"Obj1's value after invalid setter input: {obj1.value}\")\n","\n","print(\"\\n--- Using the __str__ method ---\")\n","# Input: The object itself\n","# Output: The string returned by __str__\n","print(obj1)\n","print(obj2)\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Creating Instances ---\n","Instance 'First Object' created with initial value 10.\n","Instance 'Second Object' created with initial value 20.\n","\n","--- Accessing Class Attributes ---\n","Class attribute type: Blueprint Example\n","Total instances created: 2\n","\n","--- Accessing Instance Attributes ---\n","Obj1's name: First Object, status: Active\n","Obj2's name: Second Object, status: Active\n","\n","--- Calling Methods ---\n","Value for 'First Object' incremented to 11.\n","Value for 'First Object' incremented to 16.\n","Value for 'Second Object' incremented to 30.\n","\n","--- Using the get_info method ---\n","Info for obj1: Name: First Object, Current Value: 16, Status: Active\n","Info for obj2: Name: Second Object, Current Value: 30, Status: Active\n","\n","--- Using the Property (Getter) ---\n","Accessing value property...\n","Obj1's current value (via property): 16\n","\n","--- Using the Property (Setter) ---\n","Value for 'First Object' updated to 100.\n","Accessing value property...\n","Obj1's updated value: 100\n","Warning: Value cannot be negative. Setting to 0.\n","Accessing value property...\n","Obj1's value after invalid setter input: 0\n","\n","--- Using the __str__ method ---\n","<MyExampleClass Object: Name='First Object', Value=0>\n","<MyExampleClass Object: Name='Second Object', Value=30>\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","\n","# 1. Create a \"messy\" dataset with words\n","data = {\n","    'Size': [1500, 2000, 1200, 1800],\n","    'Color': ['Red', 'Blue', 'Red', 'Green'], # Words!\n","    'Price': [250000, 300000, 200000, 280000]\n","}\n","df = pd.DataFrame(data)\n","\n","# 2. Separate Features (X) and Target (y)\n","X = df[['Size', 'Color']]\n","y = df['Price']\n","\n","# 3. Use ColumnTransformer to encode ONLY the 'Color' column\n","# We tell it: \"Apply OneHotEncoder to column 1 (Color), and leave column 0 (Size) alone.\"\n","ct = ColumnTransformer(\n","    [('encoder', OneHotEncoder(), [1])],\n","    remainder='passthrough'\n",")\n","\n","X_encoded = ct.fit_transform(X)\n","\n","print(\"Original Features:\")\n","print(X)\n","print(\"\\nEncoded Features (Ready for ML):\")\n","print(X_encoded)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yF5h5V4X_F6I","executionInfo":{"status":"ok","timestamp":1768033145877,"user_tz":480,"elapsed":305,"user":{"displayName":"Kalyani Kmas","userId":"17646635431045589522"}},"outputId":"115822c0-c5d3-4575-ff2a-b6b8ebac0478"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Features:\n","   Size  Color\n","0  1500    Red\n","1  2000   Blue\n","2  1200    Red\n","3  1800  Green\n","\n","Encoded Features (Ready for ML):\n","[[0.0e+00 0.0e+00 1.0e+00 1.5e+03]\n"," [1.0e+00 0.0e+00 0.0e+00 2.0e+03]\n"," [0.0e+00 0.0e+00 1.0e+00 1.2e+03]\n"," [0.0e+00 1.0e+00 0.0e+00 1.8e+03]]\n"]}]}]}